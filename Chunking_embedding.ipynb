{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devanshk/Desktop/All-the-rag-projects/haptic-rag/.venv/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/devanshk/Desktop/All-the-rag-projects/haptic-rag/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "import pymupdf\n",
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings, DEFAULT_TENANT, DEFAULT_DATABASE\n",
    "from chromadb.errors import InvalidCollectionException\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/devanshk/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "def process_papers_txt(folder_path: str) -> List[Dict[str, any]]:\n",
    "    \"\"\"Process each cleaned .txt file (provided from generate_clean_text_files.ipynb) in the folder and return a list of dictionaries with 'id' and 'text' keys.\"\"\"\n",
    "    papers = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "            papers.append({\n",
    "                \"id\": filename,\n",
    "                \"text\": text\n",
    "            })\n",
    "    return papers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(papers: List[Dict[str, str]], model_name: str = \"all-MiniLM-L6-v2\") -> List[Dict[str, any]]:\n",
    "    \"\"\"Create embeddings for the given papers.\"\"\"\n",
    "\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    embedded_papers = []\n",
    "    for paper in papers:\n",
    "        embedding = model.encode(paper[\"text\"])\n",
    "        embedded_papers.append({\n",
    "            \"id\": paper[\"id\"],\n",
    "            \"text\": paper[\"text\"],\n",
    "            \"embedding\": embedding.tolist()\n",
    "        })\n",
    "    return embedded_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_chroma(papers: List[Dict[str, any]], collection_name: str = \"research_papers\") -> chromadb.Collection:\n",
    "    \"\"\"Store the embedded papers in Chroma vector database.\"\"\"\n",
    "    client = chromadb.PersistentClient(settings=Settings(),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE)\n",
    "    \n",
    "    # Check if collection exists, if not create it\n",
    "    try:\n",
    "        collection = client.get_collection(name=collection_name)\n",
    "    except InvalidCollectionException:\n",
    "        collection = client.create_collection(name=collection_name)\n",
    "    \n",
    "    ids = [paper[\"id\"] for paper in papers]\n",
    "    embeddings = [paper[\"embedding\"] for paper in papers]\n",
    "    documents = [paper[\"text\"] for paper in papers]\n",
    "    \n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        embeddings=embeddings,\n",
    "        documents=documents\n",
    "    )\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_chunking(text: str, model_name: str = \"all-MiniLM-L6-v2\") -> List[str]:\n",
    "    \"\"\"Chunk the text using semantic similarity.\"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    chunks = []\n",
    "    sentences = sent_tokenize(text)\n",
    "    current_chunk = sentences[0]\n",
    "\n",
    "    for sentence in sentences[1:]:\n",
    "        current_chunk_embedding = model.encode(current_chunk)\n",
    "        sentence_embedding = model.encode(sentence)\n",
    "        similarity = model.similarity(current_chunk_embedding, sentence_embedding)\n",
    "        if similarity > 0.8:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence    \n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_fixed_size(text: str, chunk_size: int = 1000, overlap: int = 100) -> List[str]:\n",
    "    \"\"\"Chunk the text into fixed-size chunks with overlap.\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "\n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += (chunk_size - overlap)\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_sentence(text: str, max_chunk_size: int = 1000) -> List[str]:\n",
    "    \"\"\"Chunk the text by sentences, ensuring chunks don't exceed max_chunk_size.\"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chroma(query: str, collection: chromadb.Collection, top_k: int = 5) -> List[Dict[str, any]]:\n",
    "    \"\"\"Query the Chroma database and return the top_k most relevant results.\"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # Reformat results for easier handling\n",
    "    formatted_results = []\n",
    "    for i in range(len(results['ids'][0])):\n",
    "        formatted_results.append({\n",
    "            'id': results['ids'][0][i],\n",
    "            'text': results['documents'][0][i],\n",
    "            'distance': results['distances'][0][i]\n",
    "        })\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 most relevant chunks:\n",
      "\n",
      "1. Document: Eng_haptic_devices978_3_031_04536_3_pdf.txt_chunk_1\n",
      "Relevance Score: 0.4841\n",
      "Text: it is focused on publishing new advances and developments\n",
      "in all aspects of haptics. haptics is a multidisciplinary eld with researchers from\n",
      "psychology, physiology, neurology, engineering, and comput...\n",
      "\n",
      "2. Document: Eng_haptic_devices_978_3_031_04536_3_pdf.txt_chunk_1\n",
      "Relevance Score: 0.4841\n",
      "Text: it is focused on publishing new advances and developments\n",
      "in all aspects of haptics. haptics is a multidisciplinary eld with researchers from\n",
      "psychology, physiology, neurology, engineering, and comput...\n",
      "\n",
      "3. Document: 978_3_030_24564_1_pdf.txt_chunk_130\n",
      "Relevance Score: 0.4490\n",
      "Text: primarily technologies being developed for digital touch communication involve \n",
      "some form of haptics. haptics investigates humanmachine communication \n",
      "through the sense of touch in interactions where ...\n",
      "\n",
      "4. Document: Electromechanical_Actuators_for_Haptic_Feedback_with_Fingertip_Contact_2023_MDPI_pdf.txt_chunk_3\n",
      "Relevance Score: 0.4488\n",
      "Text: haptics, also\n",
      "connected with touch sensing, refers to the ability to apply both tactile and kinesthetic\n",
      "sensations to humancomputer interactions, which often relies on the largest active organ of\n",
      "the ...\n",
      "\n",
      "5. Document: Eng_haptic_devices_978_3_031_04536_3_pdf.txt_chunk_22\n",
      "Relevance Score: 0.4299\n",
      "Text: haptics\n",
      "as an interaction modality is discussed as a basis for the design of such systems. this includes various concepts of haptic perception and haptic interaction, as well\n",
      "preface\n",
      "as the main resul...\n",
      "\n",
      "Top 5 most relevant chunks:\n",
      "\n",
      "1. Document: Silent_persuasion_Incidental_use_of_promotional_merchandise_benefits_unfamiliar_brands_2021_Taylor_and_Francis_Ltd_pdf.txt_chunk_17\n",
      "Relevance Score: -0.4528\n",
      "Text: for instance, janiszewski (1988) found that precon\n",
      "scious exposure to a print ad affects evaluation of the print ad. in addition, some evi\n",
      "dence suggests that the effect of visual exposure may general...\n",
      "\n",
      "2. Document: Silent_persuasion_Incidental_use_of_promotional_merchandise_benefits_unfamiliar_brands_2021_Taylor_and_Francis_Ltd_pdf.txt_chunk_3\n",
      "Relevance Score: -0.4724\n",
      "Text: that is, consumers temporar\n",
      "ily use these items for a specific purpose but the item itself is secondary and consum\n",
      "ers do not pay much attention to it. notably, all of these items often are promotiona...\n",
      "\n",
      "3. Document: Silent_persuasion_Incidental_use_of_promotional_merchandise_benefits_unfamiliar_brands_2021_Taylor_and_Francis_Ltd_pdf.txt_chunk_53\n",
      "Relevance Score: -0.4968\n",
      "Text: the merchandise is\n",
      "b. kamleitner and e. marckhgott\n",
      "used incidentally, and consumers can easily miss the promotional message the mer\n",
      "chandise carries. this research is the first to show that promotiona...\n",
      "\n",
      "4. Document: Silent_persuasion_Incidental_use_of_promotional_merchandise_benefits_unfamiliar_brands_2021_Taylor_and_Francis_Ltd_pdf.txt_chunk_24\n",
      "Relevance Score: -0.4980\n",
      "Text: as\n",
      "one of these marketing and advertising media (cooper 2009), promotional merchandise\n",
      "competes with the complete range of advertising techniques and channels. the question\n",
      "thus arises how the inciden...\n",
      "\n",
      "5. Document: How_multisensory_perception_promotes_purchase_intent_in_the_context_of_clothing_ecustomisation_2022_Frontiers_Media_SA_pdf.txt_chunk_7\n",
      "Relevance Score: -0.5024\n",
      "Text: advertisements \n",
      "that provide attractive pictures and videos to consumers that may \n",
      "help them to get connection with the products in online shopping \n",
      "(charoensereechai etal., 2022). both pictorial info...\n"
     ]
    }
   ],
   "source": [
    "def main(folder_path: str, chunking_method: str = \"sentence\"):\n",
    "    \"\"\"Main function to run the RAG pipeline.\"\"\"\n",
    "    print(\"Processing papers...\")\n",
    "    papers = process_papers_txt(folder_path)\n",
    "    \n",
    "    print(\"Chunking papers...\")\n",
    "    chunked_papers = []\n",
    "    for paper in papers:\n",
    "        if chunking_method == \"fixed\":\n",
    "            chunks = chunk_by_fixed_size(paper[\"text\"])\n",
    "        elif chunking_method == \"sentence\":\n",
    "            chunks = chunk_by_sentence(paper[\"text\"])\n",
    "        elif chunking_method == \"semantic\":\n",
    "            chunks = semantic_chunking(paper[\"text\"])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid chunking method. Choose 'fixed' or 'sentence' or 'semantic'.\")\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunked_papers.append({\n",
    "                \"id\": f\"{paper['id']}_chunk_{i}\",\n",
    "                \"text\": chunk\n",
    "            })\n",
    "    \n",
    "    print(\"Creating embeddings...\")\n",
    "    embedded_papers = create_embeddings(chunked_papers)\n",
    "    \n",
    "    # Splitting embedded_papers into smaller batches to avoid exceeding the maximum batch size\n",
    "    max_batch_size = 5000\n",
    "    print(\"Storing in Chroma database...\")\n",
    "    for i in range(0, len(embedded_papers), max_batch_size):\n",
    "        batch = embedded_papers[i:i + max_batch_size]\n",
    "        store_in_chroma(batch)\n",
    "    \n",
    "    print(\"Pipeline completed successfully!\")\n",
    "    # # Query loop Uncomment if wanting to test if the \n",
    "    # while True:\n",
    "    #     query = input(\"Enter your query (or 'quit' to exit): \")\n",
    "    #     if query.lower() == 'quit':\n",
    "    #         break\n",
    "        \n",
    "    #     results = query_chroma(query, collection)\n",
    "    #     print(\"\\nTop 5 most relevant chunks:\")\n",
    "    #     for i, result in enumerate(results, 1):\n",
    "    #         print(f\"\\n{i}. Document: {result['id']}\")\n",
    "    #         print(f\"Relevance Score: {1 - result['distance']:.4f}\")\n",
    "    #         print(f\"Text: {result['text'][:200]}...\")  # Print first 200 characters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"cleaned_text\"  # Set the path to your folder containing the .txt files from the generate_clean_text_files.ipynb\n",
    "    chunking_method = \"sentence\"  # Choose the semantic strategy that you want to use\n",
    "    main(folder_path, chunking_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
